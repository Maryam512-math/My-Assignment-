{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yR6NFppnElxQHW3QcJuSx7ixJ6NvGpRd",
      "authorship_tag": "ABX9TyPEwT3cik/PaVMgsCmfONdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maryam512-math/My-Assignment-/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xi7BC9K0L1f5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/CVD_cleaned.csv\")\n",
        "data.dropna(axis=1, inplace=True)\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "data['Heart_Disease'] = le.fit_transform(data['Heart_Disease'])\n",
        "\n",
        "X = data.drop('Heart_Disease', axis=1)\n",
        "y = data['Heart_Disease']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Create preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)])\n",
        "\n",
        "# Create a pipeline that first preprocesses the data and then scales it\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply preprocessing to training and testing data\n",
        "X_train_processed = pipeline.fit_transform(X_train)\n",
        "X_test_processed = pipeline.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_processed, y_train)\n",
        "y_pred_lr = lr.predict(X_test_processed)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_lr, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8fPazszL89H",
        "outputId": "d0ad51ac-10aa-4ed9-aa84-4c6cbcc64f10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Accuracy: 0.9192177559048744\n",
            "F1 Score: 0.889279876451409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save model\n",
        "joblib.dump(lr, \"logistic_regression_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUw94TQvVCks",
        "outputId": "0a0ab635-d0ba-480c-c317-653313989bdb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logistic_regression_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "rFk90FnSfPRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_processed, y_train)\n",
        "y_pred_rf = rf.predict(X_test_processed)\n",
        "\n",
        "print(\"Random Forest\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_rf, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr_-wBssL9Yj",
        "outputId": "ba17ba2d-80a6-4381-eb40-fefe747e4aa6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "Accuracy: 0.91835974810186\n",
            "F1 Score: 0.8869654783246659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(rf, \"random_forest_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIgeoVZZWAnC",
        "outputId": "3f2a5637-4c83-42cd-f390-73a9cdfc120d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_processed, y_train)\n",
        "y_pred_knn = knn.predict(X_test_processed)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_knn, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWEc_ZJNMGhT",
        "outputId": "97a5fdf5-48e0-4b49-b4ed-930455d55f1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN\n",
            "Accuracy: 0.9101843907335158\n",
            "F1 Score: 0.8873443021475063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Prepare labels for Keras\n",
        "num_classes = len(np.unique(y))\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "model_dl = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=X_train_processed.shape[1]),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_dl.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_dl.fit(X_train_processed, y_train_cat, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "y_pred_dl = model_dl.predict(X_test_processed).argmax(axis=1)\n",
        "\n",
        "print(\"Deep Learning\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dl))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_dl, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH5XkSK7MMjN",
        "outputId": "d19f587b-cd27-46db-d75f-c47580c24ab5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2374\n",
            "Epoch 2/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2262\n",
            "Epoch 3/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2243\n",
            "Epoch 4/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2249\n",
            "Epoch 5/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2254\n",
            "Epoch 6/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2234\n",
            "Epoch 7/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2246\n",
            "Epoch 8/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2238\n",
            "Epoch 9/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9198 - loss: 0.2234\n",
            "Epoch 10/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2254\n",
            "Epoch 11/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2249\n",
            "Epoch 12/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2246\n",
            "Epoch 13/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2229\n",
            "Epoch 14/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2252\n",
            "Epoch 15/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2223\n",
            "Epoch 16/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2269\n",
            "Epoch 17/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2243\n",
            "Epoch 18/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2231\n",
            "Epoch 19/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2245\n",
            "Epoch 20/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2233\n",
            "Epoch 21/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2244\n",
            "Epoch 22/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2258\n",
            "Epoch 23/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2262\n",
            "Epoch 24/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9199 - loss: 0.2233\n",
            "Epoch 25/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2254\n",
            "Epoch 26/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2254\n",
            "Epoch 27/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2244\n",
            "Epoch 28/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2238\n",
            "Epoch 29/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2228\n",
            "Epoch 30/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2232\n",
            "Epoch 31/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2250\n",
            "Epoch 32/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2220\n",
            "Epoch 33/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9199 - loss: 0.2227\n",
            "Epoch 34/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2252\n",
            "Epoch 35/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2249\n",
            "Epoch 36/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2251\n",
            "Epoch 37/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2221\n",
            "Epoch 38/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2236\n",
            "Epoch 39/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2236\n",
            "Epoch 40/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2230\n",
            "Epoch 41/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2230\n",
            "Epoch 42/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2241\n",
            "Epoch 43/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2238\n",
            "Epoch 44/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2233\n",
            "Epoch 45/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2223\n",
            "Epoch 46/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2222\n",
            "Epoch 47/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2235\n",
            "Epoch 48/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2262\n",
            "Epoch 49/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2233\n",
            "Epoch 50/50\n",
            "\u001b[1m15443/15443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2254\n",
            "\u001b[1m1931/1931\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step\n",
            "Deep Learning\n",
            "Accuracy: 0.9193958329960661\n",
            "F1 Score: 0.8830927482843656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhfLV76ESdZR",
        "outputId": "b18c488e-8928-4cda-90e8-7108dbc0daeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.47.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.47.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Load trained model and label encoder\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    # Get the current working directory\n",
        "    current_dir = os.getcwd()\n",
        "    model_path = os.path.join(current_dir, \"random_forest_model.pkl\")\n",
        "    encoder_path = os.path.join(current_dir, \"label_encoder.pkl\")\n",
        "    symptoms_path = os.path.join(current_dir, \"symptom_list.pkl\")\n",
        "\n",
        "    try:\n",
        "        with open(model_path, \"rb\") as f:\n",
        "            model = pickle.load(f)\n",
        "        with open(encoder_path, \"rb\") as f:\n",
        "            encoder = pickle.load(f)\n",
        "        with open(symptoms_path, \"rb\") as f:\n",
        "            symptoms = pickle.load(f)\n",
        "        return model, encoder, symptoms\n",
        "    except FileNotFoundError as e:\n",
        "        st.error(f\"Error loading model files: {e}. Make sure you have run the cells to save the model and encoder.\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "model, label_encoder, all_symptoms = load_model()\n",
        "\n",
        "if model and label_encoder and all_symptoms:\n",
        "    # Title\n",
        "    st.title(\"Disease Prediction from Symptoms\")\n",
        "    st.write(\"Input the presence (1) or absence (0) of symptoms below:\")\n",
        "\n",
        "    # User input\n",
        "    user_input = {}\n",
        "    for symptom in all_symptoms:\n",
        "        user_input[symptom] = st.selectbox(f\"{symptom.replace('_',' ').capitalize()}\", [0, 1], key=symptom)\n",
        "\n",
        "    # Prediction\n",
        "    if st.button(\"Predict Disease\"):\n",
        "        input_df = pd.DataFrame([user_input])\n",
        "        prediction = model.predict(input_df)[0]\n",
        "        disease_name = label_encoder.inverse_transform([prediction])[0]\n",
        "        st.success(f\"🩺 Predicted Disease: **{disease_name}**\")\n",
        "else:\n",
        "    st.warning(\"Model files not loaded. Please run the cells to save the model and encoder, then rerun this cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-BRWgojSpIh",
        "outputId": "dfc6270c-7093-4eb3-ee8b-99f6ef83aecd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-23 08:14:51.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:14:51.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:14:51.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved model\n",
        "model = joblib.load(\"logistic_regression_model.pkl\")\n",
        "\n",
        "# Create a dictionary with example feature values (replace with actual values)\n",
        "# The keys should match the original column names of your data (excluding the target)\n",
        "example_input = {\n",
        "    'General_Health': 'Very Good',\n",
        "    'Checkup': 'Within the past year',\n",
        "    'Exercise': 'Yes',\n",
        "    'Skin_Cancer': 'No',\n",
        "    'Other_Cancer': 'No',\n",
        "    'Depression': 'No',\n",
        "    'Diabetes': 'No',\n",
        "    'Arthritis': 'No',\n",
        "    'Sex': 'Female',\n",
        "    'Age_Category': '55-59',\n",
        "    'Height_(cm)': 163.0,\n",
        "    'Weight_(kg)': 75.0,\n",
        "    'BMI': 28.37,\n",
        "    'Smoking_History': 'Yes',\n",
        "    'Alcohol_Consumption': 0.0,\n",
        "    'Fruit_Consumption': 30.0,\n",
        "    'Green_Vegetables_Consumption': 16.0,\n",
        "    'FriedPotato_Consumption': 12.0\n",
        "}\n",
        "\n",
        "\n",
        "# Convert the example input to a DataFrame\n",
        "input_df = pd.DataFrame([example_input])\n",
        "\n",
        "# Preprocess the input data using the same pipeline used for training\n",
        "# Make sure the 'pipeline' variable is defined in a previous cell and has been fitted on the training data\n",
        "try:\n",
        "    input_processed = pipeline.transform(input_df)\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(input_processed)[0]\n",
        "\n",
        "    # Assuming you have the label_encoder from the first cell\n",
        "    # If not, you might need to load it or recreate it\n",
        "    # For demonstration, let's assume 0 and 1 are the encoded classes\n",
        "    predicted_class = \"No Heart Disease\" if prediction == 0 else \"Heart Disease\"\n",
        "\n",
        "    st.write(\"Prediction:\", predicted_class)\n",
        "\n",
        "except NameError:\n",
        "    st.error(\"The 'pipeline' object is not defined. Please run the first cell to define and fit the preprocessing pipeline.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"An error occurred during prediction: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nWWMDWvSzW2",
        "outputId": "ee7e2e96-531e-4bbc-95a4-52ff4f84ad43"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8yaOrfvS-Qy",
        "outputId": "bae3a9aa-5e7a-45dc-d8e0-b475bd96ba9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2zuJuuww7wEH0TCZr10f8Eo7RBS_2CWSdiVDVie8PCSgnTBA6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRGIUgOXTC__",
        "outputId": "4933afdf-b456-4cc3-ea1a-f78460602588"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n",
        "\n",
        "# Run streamlit\n",
        "!streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vW1jy8HTICe",
        "outputId": "3ed689c1-6040-4f6b-cb11-3af01a50c804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://968e0a9fea52.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.46.115.249:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved model\n",
        "model = joblib.load(\"logistic_regression_model.pkl\")\n",
        "\n",
        "# Create a dictionary with example feature values (replace with actual values)\n",
        "# The keys should match the original column names of your data (excluding the target)\n",
        "example_input = {\n",
        "    'General_Health': 'Very Good',\n",
        "    'Checkup': 'Within the past year',\n",
        "    'Exercise': 'Yes',\n",
        "    'Skin_Cancer': 'No',\n",
        "    'Other_Cancer': 'No',\n",
        "    'Depression': 'No',\n",
        "    'Diabetes': 'No',\n",
        "    'Arthritis': 'No',\n",
        "    'Sex': 'Female',\n",
        "    'Age_Category': '55-59',\n",
        "    'Height_(cm)': 163.0,\n",
        "    'Weight_(kg)': 75.0,\n",
        "    'BMI': 28.37,\n",
        "    'Smoking_History': 'Yes',\n",
        "    'Alcohol_Consumption': 0.0,\n",
        "    'Fruit_Consumption': 30.0,\n",
        "    'Green_Vegetables_Consumption': 16.0,\n",
        "    'FriedPotato_Consumption': 12.0\n",
        "}\n",
        "\n",
        "\n",
        "# Convert the example input to a DataFrame\n",
        "input_df = pd.DataFrame([example_input])\n",
        "\n",
        "# Preprocess the input data using the same pipeline used for training\n",
        "# Make sure the 'pipeline' variable is defined in a previous cell and has been fitted on the training data\n",
        "try:\n",
        "    input_processed = pipeline.transform(input_df)\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(input_processed)[0]\n",
        "\n",
        "    # Assuming you have the label_encoder from the first cell\n",
        "    # If not, you might need to load it or recreate it\n",
        "    # For demonstration, let's assume 0 and 1 are the encoded classes\n",
        "    predicted_class = \"No Heart Disease\" if prediction == 0 else \"Heart Disease\"\n",
        "\n",
        "    st.write(\"Prediction:\", predicted_class)\n",
        "\n",
        "except NameError:\n",
        "    st.error(\"The 'pipeline' object is not defined. Please run the first cell to define and fit the preprocessing pipeline.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"An error occurred during prediction: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtaNR6eZUdUb",
        "outputId": "121ffcc0-b901-4111-fd6f-dac8ec3a7a33"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-23 08:16:38.571 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:16:38.571 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:16:38.572 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:16:38.574 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:16:38.575 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-23 08:16:38.576 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# In Streamlit\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "scaled_input = scaler.transform([user_input])\n"
      ],
      "metadata": {
        "id": "rYW_KAxZUkF_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}